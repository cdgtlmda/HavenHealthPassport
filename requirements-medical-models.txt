# Medical Embedding Models Dependencies
# These are required for the vector_store.medical_embeddings module to use real models
# instead of mock/fallback embeddings

# Core ML/DL Framework
torch>=2.0.0  # PyTorch for neural network operations

# Hugging Face Transformers
transformers>=4.36.0  # For loading BioBERT, ClinicalBERT, SciBERT models
tokenizers>=0.15.0    # Fast tokenizers for transformer models
datasets>=2.14.0      # For loading medical datasets (optional)

# Sentence Transformers  
sentence-transformers>=2.2.0  # For semantic similarity and embedding models

# Medical-Specific Models Available (automatically downloaded on first use):
# - pritamdeka/S-PubMedBert-MS-MARCO: PubMedBERT fine-tuned for medical semantic search
# - kamalkraj/BioSimCSE-BioLinkBERT-BASE: BioLinkBERT for medical similarity  
# - emilyalsentzer/Bio_ClinicalBERT: Trained on MIMIC-III clinical notes
# - dmis-lab/biobert-v1.1: BioBERT trained on PubMed abstracts
# - microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext: Microsoft's PubMedBERT
# - allenai/scibert_scivocab_uncased: SciBERT for scientific text

# Supporting Libraries
scipy>=1.10.0         # For similarity calculations
scikit-learn>=1.3.0   # For clustering and additional ML utilities
faiss-cpu>=1.7.4      # For efficient similarity search (optional, install faiss-gpu for GPU)

# Optional GPU Support
# accelerate>=0.20.0  # For distributed training/inference
# bitsandbytes>=0.40.0  # For 8-bit quantization to reduce memory usage

# Optional Medical NLP Libraries (for enhanced processing)
# scispacy>=0.5.3     # Scientific/medical spaCy models
# medspacy>=1.1.2     # Clinical NLP pipelines
# negspacy>=1.0.3     # Negation detection in medical text
 will continue to function but with severely degraded search and similarity matching

### Memory Issues

If running out of memory:
```python
# Use smaller model
service = MedicalEmbeddingService(model_name="sentence-transformers/all-MiniLM-L6-v2")

# Or use CPU only
service = MedicalEmbeddingService(device="cpu")
```

## Privacy & Compliance

All models run **locally** - no data is sent to external services:
- Models download once and cache locally
- All inference happens on your hardware
- No API calls to external services
- HIPAA compliant as no PHI leaves your system

## License Information

All recommended models are open source:
- **BioBERT**: Apache 2.0
- **ClinicalBERT**: MIT  
- **SciBERT**: Apache 2.0
- **PubMedBERT**: MIT

Free to use in commercial applications including healthcare systems.
